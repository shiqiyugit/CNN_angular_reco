#!/bin/bash --login

########### SBATCH Lines for Resource Request ##########

#SBATCH --time=23:59:00             # limit of wall clock time - how long the job will run (same as -t)
#SBATCH --nodes=1                 # number of different nodes - could be an exact number or a range of nodes (same as -N)
#SBATCH --mem-per-cpu=100G            # memory required per allocated CPU (or core) - amount of memory (in bytes)
#SBATCH --job-name offjob   # you can give your job a name for easier identification (same as -J)
#SBATCH --output job_logs/@@name@@

########### Command Lines to Run ##########

INDIR=/mnt/home/yushiqi2/Analysis/LowEnergyNeuralNetwork/data_pre


source /mnt/home/yushiqi2/Documents/setup_anaconda.sh

#python $INDIR/flatten_zenith_distribution.py -i @@infile@@ -d "@@dir@@" -o @@name@@ --max_per_bin @@bin_max@@ --cuts @@cuts@@ --num_out 1 --start "contained_IC19_start" --end "contained_IC19_end" --transformed --shuffle --emax 300 -od @@outdir@@ --split 

#python $INDIR/flatten_zenith_distribution.py -i @@infile@@ -d "@@dir@@" -o @@name@@ --max_per_bin @@bin_max@@ --cuts @@cuts@@ --num_out 1 --start "all_start" --end "all_end" --transformed --shuffle --emax 300 -od @@outdir@@ --emin 1 --split

python $INDIR/flatten_zenith_distribution.py -i @@infile@@ -d "@@dir@@" -o @@name@@ --max_per_bin @@bin_max@@ --cuts @@cuts@@ --num_out 1 --start "all_start" --end "all_end" --transformed --shuffle --emax 1000 -od @@outdir@@ --emin 1 --split --reco --no_flatten

#python $INDIR/flatten_zenith_distribution.py -i @@infile@@ -d "@@dir@@" -o @@name@@ --max_per_bin @@bin_max@@ --cuts @@cuts@@ --num_out 1 --start "contained_IC19_start" --end "all_end" --transformed --shuffle --emax 300 -od @@outdir@@ --emin 5 --split


exit $?

